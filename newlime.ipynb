{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTVA7PrLK-WF"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from anchor import utils\n",
    "\n",
    "import time\n",
    "import csv\n",
    "import newlime_utils\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "def sample(index, dataset, dataset_name, dataset_folder, write_file=False):\n",
    "    trg, label, tab = newlime_utils.get_trg_sample(index, dataset, dataset_name)\n",
    "    \n",
    "    print('Prediction:', dataset.class_names[rf.predict(trg.reshape(1, -1))[0]])\n",
    "    print('True:      ', dataset.class_names[dataset.labels_test[index]])\n",
    "    print(tabulate(tab))\n",
    "    if write_file:\n",
    "        with open('img/%s/%05d-instance.csv' % (dataset_name, index), 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows([['feature', 'value']])\n",
    "            writer.writerows(tab)\n",
    "    return trg, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import explanation\n",
    "from lime import lime_tabular\n",
    "\n",
    "def lime_original(trg, pred_label):\n",
    "    lime_explainer = lime_tabular.LimeTabularExplainer(\n",
    "        dataset.train,\n",
    "        feature_names=dataset.feature_names,\n",
    "        class_names=dataset.class_names,\n",
    "        discretize_continuous=False)\n",
    "    lime_exp = lime_explainer.explain_instance(\n",
    "        trg, rf.predict_proba, num_features=5, top_labels=1)\n",
    "    # lime_exp.show_in_notebook(show_table=True, show_all=True)\n",
    "    weights = [0] * len(dataset.feature_names)\n",
    "    for t in lime_exp.local_exp[pred_label]:\n",
    "        weights[t[0]] = t[1] * (pred_label * 2 - 1)\n",
    "    newlime_utils.plot_weights(weights, dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import anchor_tabular\n",
    "\n",
    "def anchor_original(trg, threshold=0.85):\n",
    "    anchor_explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "        dataset.class_names,\n",
    "        dataset.feature_names,\n",
    "        dataset.train,\n",
    "        dataset.categorical_names)\n",
    "    anchor_exp = anchor_explainer.explain_instance(\n",
    "        trg, rf.predict, threshold)\n",
    "\n",
    "    print('Threshold:  %.2f' % threshold)\n",
    "    # print('Prediction:', anchor_explainer.class_names[rf.predict(trg.reshape(1, -1))[0]])\n",
    "    print('Anchor:     %s' % (' AND '.join(anchor_exp.names())))\n",
    "    print('Precision:  %.2f' % anchor_exp.precision())\n",
    "    print('Coverage:   %.2f' % anchor_exp.coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newlime_base\n",
    "import newlime_tabular\n",
    "import newlime_utils\n",
    "\n",
    "def new_lime(trg, dataset, threshold, epsilon, beam_size, my_verbose):\n",
    "    print(\"-----------\")\n",
    "    print(\"Threshold: \", threshold)\n",
    "    anchor_explainer = newlime_tabular.NewLimeTabularExplainer(\n",
    "        dataset.class_names,\n",
    "        dataset.feature_names,\n",
    "        dataset.train,\n",
    "        dataset.categorical_names)\n",
    "    anchor_exp, surrogate_model = anchor_explainer.explain_instance(\n",
    "        trg, rf.predict, threshold=threshold, epsilon=epsilon, beam_size=10)\n",
    "    names = anchor_exp.names()\n",
    "    multiline_names = []\n",
    "    max_i = int(len(names) / 3)\n",
    "    for i in range(max_i):\n",
    "        triple = [names[i * 3], names[i * 3 + 1], names[i * 3 + 2]]\n",
    "        multiline_names.append(' AND '.join(triple))\n",
    "    if len(names) != max_i* 3:\n",
    "        multiline_names.append(' AND '.join(names[max_i * 3:]))\n",
    "\n",
    "    weights = list(surrogate_model['LogisticRegression'].weights.values())\n",
    "    feat = dataset.feature_names\n",
    "    rule = ' AND \\n'.join(multiline_names)\n",
    "    prec = anchor_exp.precision()\n",
    "    cov = anchor_exp.coverage()\n",
    "    print(\"Rule     : \", rule)\n",
    "    print(\"Precision: \", prec)\n",
    "    print(\"Coverage : \", cov)\n",
    "    \n",
    "    if weights == []:\n",
    "        print(\"Error! Surrogate model has no weights!\")\n",
    "    else:\n",
    "        newlime_utils.plot_weights(weights, feat, rule, prec, cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTVA7PrLK-WF"
   },
   "source": [
    "## Generating Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1693384132186,
     "user": {
      "displayName": "大原玄嗣",
      "userId": "17130663518414586879"
     },
     "user_tz": -540
    },
    "id": "Mk7wsr1rYrMm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12545\n",
      "1569\n",
      "14114\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = 'datasets/'\n",
    "# dataset_name = 'recidivism'\n",
    "dataset_name = 'adult'\n",
    "# dataset_name = 'diabetes'\n",
    "# dataset_name = 'default'\n",
    "# dataset_name = 'lending'\n",
    "\n",
    "dataset = utils.load_dataset(\n",
    "    dataset_name, balance=True, dataset_folder=dataset_folder, discretize=True)\n",
    "\n",
    "print(dataset.train.shape[0])\n",
    "print(dataset.test.shape[0])\n",
    "print(dataset.train.shape[0] + dataset.test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13566,
     "status": "ok",
     "timestamp": 1693384148268,
     "user": {
      "displayName": "大原玄嗣",
      "userId": "17130663518414586879"
     },
     "user_tz": -540
    },
    "id": "t4zQDCB1xgXY",
    "outputId": "67f0b135-740e-45a6-f9dd-8be81469031f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.9350338780390594\n",
      "Test 0.8489483747609943\n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=50, n_jobs=5)\n",
    "rf.fit(dataset.train, dataset.labels_train)\n",
    "\n",
    "print('Train', sklearn.metrics.accuracy_score(\n",
    "    dataset.labels_train, rf.predict(dataset.train)))\n",
    "print('Test', sklearn.metrics.accuracy_score(\n",
    "    dataset.labels_test, rf.predict(dataset.test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: b'>50K'\n",
      "True:       b'>50K'\n",
      "--------------  --------------------------\n",
      "Age             28.00 < Age <= 37.00 (1)\n",
      "Workclass       Private (4)\n",
      "Education       Bachelors (9)\n",
      "Marital Status  Married-civ-spouse (2)\n",
      "Occupation      Sales (12)\n",
      "Relationship    Husband (0)\n",
      "Race            White (4)\n",
      "Sex             Male (1)\n",
      "Capital Gain    0\n",
      "Capital Loss    0\n",
      "Hours per week  Hours per week > 45.00 (2)\n",
      "Country         United-States (39)\n",
      "Income          >50K (1)\n",
      "--------------  --------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "i = random.randint(10, dataset.test.shape[0])\n",
    "\n",
    "# adult\n",
    "# 730, 956, 1196, 1522\n",
    "# i = 1443 # --- Capital Gain = 2\n",
    "i = 0\n",
    "\n",
    "# recidivism\n",
    "# i = 266\n",
    "# i = 599\n",
    "\n",
    "trg, trg_label = sample(i, dataset, dataset_name, dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1693384151469,
     "user": {
      "displayName": "大原玄嗣",
      "userId": "17130663518414586879"
     },
     "user_tz": -540
    },
    "id": "WpL00B8X06dT",
    "outputId": "5c352fb5-d9ec-461c-bed8-dc13f8972a57",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: b'>50K'\n",
      "True:       b'>50K'\n",
      "--------------  --------------------------\n",
      "Age             28.00 < Age <= 37.00 (1)\n",
      "Workclass       Private (4)\n",
      "Education       Bachelors (9)\n",
      "Marital Status  Married-civ-spouse (2)\n",
      "Occupation      Sales (12)\n",
      "Relationship    Husband (0)\n",
      "Race            White (4)\n",
      "Sex             Male (1)\n",
      "Capital Gain    0\n",
      "Capital Loss    0\n",
      "Hours per week  Hours per week > 45.00 (2)\n",
      "Country         United-States (39)\n",
      "Income          >50K (1)\n",
      "--------------  --------------------------\n",
      "-----------\n",
      "Threshold:  0.7\n",
      "Hoow!\n",
      "Hoow!\n",
      "Hoow!\n",
      "Hoow!\n",
      "Hoow!\n",
      "Hoow!\n",
      "Hoow!\n",
      "Hoow!\n",
      "Hoow!\n",
      "Hoow!\n",
      "Hoow!\n",
      "Hoow!\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m trg, trg_label \u001b[38;5;241m=\u001b[39m sample(i, dataset, dataset_name, dataset_folder)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.70\u001b[39m, \u001b[38;5;241m0.80\u001b[39m, \u001b[38;5;241m0.90\u001b[39m, \u001b[38;5;241m0.95\u001b[39m]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mnew_lime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m write_file:\n\u001b[1;32m     14\u001b[0m         img_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%05d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m%03d\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (dataset_name, i, t \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mnew_lime\u001b[0;34m(trg, dataset, threshold, epsilon, beam_size, my_verbose)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThreshold: \u001b[39m\u001b[38;5;124m\"\u001b[39m, threshold)\n\u001b[1;32m      8\u001b[0m anchor_explainer \u001b[38;5;241m=\u001b[39m newlime_tabular\u001b[38;5;241m.\u001b[39mNewLimeTabularExplainer(\n\u001b[1;32m      9\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mclass_names,\n\u001b[1;32m     10\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mfeature_names,\n\u001b[1;32m     11\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mtrain,\n\u001b[1;32m     12\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mcategorical_names)\n\u001b[0;32m---> 13\u001b[0m anchor_exp, surrogate_model \u001b[38;5;241m=\u001b[39m \u001b[43manchor_explainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m names \u001b[38;5;241m=\u001b[39m anchor_exp\u001b[38;5;241m.\u001b[39mnames()\n\u001b[1;32m     16\u001b[0m multiline_names \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/GitHub/UserExperimentForNewLIME/NewLIME/newlime_tabular.py:168\u001b[0m, in \u001b[0;36mNewLimeTabularExplainer.explain_instance\u001b[0;34m(self, data_row, classifier_fn, threshold, delta, epsilon, batch_size, beam_size)\u001b[0m\n\u001b[1;32m    159\u001b[0m hyper_param \u001b[38;5;241m=\u001b[39m newlime_base\u001b[38;5;241m.\u001b[39mHyperParam(\n\u001b[1;32m    160\u001b[0m     delta\u001b[38;5;241m=\u001b[39mdelta,\n\u001b[1;32m    161\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39mepsilon,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     beam_size\u001b[38;5;241m=\u001b[39mbeam_size,\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    167\u001b[0m result: \u001b[38;5;28mtuple\u001b[39m[Anchor, compose\u001b[38;5;241m.\u001b[39mPipeline \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mNewLimeBaseBeam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyper_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# *********************************************************************\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/GitHub/UserExperimentForNewLIME/NewLIME/newlime_base.py:490\u001b[0m, in \u001b[0;36mNewLimeBaseBeam.beam_search\u001b[0;34m(sample_fn, hyper_param)\u001b[0m\n\u001b[1;32m    486\u001b[0m best_cand: RuleClass \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# Call 'LargestValidCand' and get the candidate rule with the\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;66;03m# highest coverage in the best B candidate rules\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m best_cand \u001b[38;5;241m=\u001b[39m \u001b[43mNewLimeBaseBeam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlargest_valid_cand\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb_best_idxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_best_cands\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyper_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_fns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43msurrogate_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_cand \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    499\u001b[0m     best_rule \u001b[38;5;241m=\u001b[39m best_cand\n",
      "File \u001b[0;32m~/GitHub/UserExperimentForNewLIME/NewLIME/newlime_base.py:316\u001b[0m, in \u001b[0;36mNewLimeBaseBeam.largest_valid_cand\u001b[0;34m(b_best_cands, hyper_param, state, sample_fns, surrogate_models)\u001b[0m\n\u001b[1;32m    307\u001b[0m beta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;241m/\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     )\n\u001b[1;32m    313\u001b[0m )\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Update confidence interval and coverage of the tuple t.\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m mean, lb, ub \u001b[38;5;241m=\u001b[39m \u001b[43mNewLimeBaseBeam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_confidence_bound\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m coverage \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt_coverage\u001b[39m\u001b[38;5;124m\"\u001b[39m][t]\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# Judge whether the tuple t is an anchor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/UserExperimentForNewLIME/NewLIME/newlime_base.py:274\u001b[0m, in \u001b[0;36mNewLimeBaseBeam.update_confidence_bound\u001b[0;34m(rule, beta, state)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_confidence_bound\u001b[39m(\n\u001b[1;32m    269\u001b[0m     rule: Rule, beta: \u001b[38;5;28mfloat\u001b[39m, state: State\n\u001b[1;32m    270\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    271\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update confidence bound of the precision of the rule based on\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m    state\"\"\"\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt_positives\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrule\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt_nsamples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrule\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    275\u001b[0m     lb \u001b[38;5;241m=\u001b[39m AnchorBaseBeam\u001b[38;5;241m.\u001b[39mdlow_bernoulli(\n\u001b[1;32m    276\u001b[0m         mean, beta \u001b[38;5;241m/\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt_nsamples\u001b[39m\u001b[38;5;124m\"\u001b[39m][rule]\n\u001b[1;32m    277\u001b[0m     )\n\u001b[1;32m    278\u001b[0m     ub \u001b[38;5;241m=\u001b[39m AnchorBaseBeam\u001b[38;5;241m.\u001b[39mdup_bernoulli(\n\u001b[1;32m    279\u001b[0m         mean, beta \u001b[38;5;241m/\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt_nsamples\u001b[39m\u001b[38;5;124m\"\u001b[39m][rule]\n\u001b[1;32m    280\u001b[0m     )\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(newlime_base)\n",
    "importlib.reload(newlime_tabular)\n",
    "importlib.reload(newlime_utils)\n",
    "write_file = False\n",
    "\n",
    "i = random.randint(10, dataset.test.shape[0])\n",
    "i = 0\n",
    "trg, trg_label = sample(i, dataset, dataset_name, dataset_folder)\n",
    "\n",
    "for t in [0.70, 0.80, 0.90, 0.95]:\n",
    "    new_lime(trg, dataset, threshold=t, beam_size=1, epsilon=0.1, my_verbose=True)\n",
    "    if write_file:\n",
    "        img_file = 'img/%s/%05d-%03d.png' % (dataset_name, i, t * 100)\n",
    "        plt.savefig(img_file, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lime_original(trg, rf.predict([dataset.test[i]])[0])\n",
    "\n",
    "write_file = False\n",
    "if write_file:\n",
    "    img_file = 'img/%s/%05d-LIME.png' % (dataset_name, i)\n",
    "    plt.savefig(img_file, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_original(trg, threshold=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN0kC9fbDNbmc0mebrwUKVT",
   "collapsed_sections": [
    "jI2l8q9vDwmC",
    "LDo-nkw4DblO",
    "FUra4f6XDkte",
    "sFuAnPY8DpwJ",
    "QYQ-Wm17JrLV",
    "wc3XCxxJJ-aX",
    "uWULnk9jKNnF",
    "xtTn_fqoKdst"
   ],
   "provenance": [
    {
     "file_id": "1BAGBj_btcdMvhdjeKv1qqb35zqofH3gh",
     "timestamp": 1691797657695
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
